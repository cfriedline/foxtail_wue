{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, tempfile, shutil\n",
    "import multiprocessing as mp\n",
    "from IPython.parallel import Client\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import clear_output, FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"huge\")\n",
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_idle_engines(rc):\n",
    "    qs = rc.queue_status()\n",
    "    time.sleep(10)\n",
    "    active = [eid for eid in sorted(qs)[:-1] if not qs[eid]['queue']]\n",
    "    d = rc[active]\n",
    "    l = rc.load_balanced_view(targets=active)\n",
    "    return d, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview, lview = get_idle_engines(rc)\n",
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with dview.sync_imports():\n",
    "    import os, stopwatch, multiprocessing, tempfile, shutil, socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_single_host_lview(host_list):\n",
    "    hosts = dview.apply(socket.gethostname).get()\n",
    "    host_ids = {}\n",
    "    for i, host in enumerate(hosts):\n",
    "        if not host in host_ids:\n",
    "            host_ids[host] = []\n",
    "        if host_list == \"all\":\n",
    "            host_ids[host].append(i)\n",
    "        elif host in host_list:\n",
    "            host_ids[host].append(i)\n",
    "    hview = [v[0] for k, v in host_ids.items()]\n",
    "    hlview = rc.load_balanced_view(targets=hview)\n",
    "    return hlview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hlview = get_single_host_lview(\"all\")\n",
    "len(hlview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembly = \"/data7/cfriedline/assemblies/foxtail2/Green_26_ATCGCGCAA.fastq_31_data_31/contigs.fa_in_map.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fastq_dir = \"/data7/eckertlab/projects/ethan/HiSeq_140603/FASTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fastq_files = !ls $fastq_dir | grep 'fastq$' | grep -v processed\n",
    "fastq_files = sorted([os.path.join(fastq_dir, x) for x in fastq_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/data7/eckertlab/projects/ethan/analysis/gatk\"\n",
    "picard = \"/home/cfriedline/data7/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/jdk1.7.0_25/bin/java\"\n",
    "bowtie2_dir = \"/home/cfriedline/data7/src/bowtie2-2.2.4\"\n",
    "bowtie2_build = os.path.join(bowtie2_dir, \"bowtie2-build\")\n",
    "bowtie2 = os.path.join(bowtie2_dir, \"bowtie2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_library_index(barcode_files):\n",
    "    index = {}\n",
    "    for f in barcode_files:\n",
    "        df = pd.read_csv(f, sep=\"\\t\")\n",
    "        names = df.apply(lambda row: \"%s_%s\" % (row.Family_ID, row.Sample_ID), axis=1)\n",
    "        for n in names:\n",
    "            if not n in index:\n",
    "                index[n] = os.path.basename(f).replace(\".csv\", \"\")\n",
    "            else:\n",
    "                print \"duplicate sample found at %s ()\" % (n, os.path.basename(f))\n",
    "    return index\n",
    "        \n",
    "library_index = create_library_index([\"/data7/eckertlab/projects/ethan/ethan_library1.csv\",\n",
    "                                      \"/data7/eckertlab/projects/ethan/ethan_library2.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sample_name_from_file(f):\n",
    "    base = os.path.basename(f)\n",
    "    sample_name = \"_\".join(base.split(\"_\")[0:2])\n",
    "    return sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_async_progress(jobs):\n",
    "    ready = 0\n",
    "    for j in jobs:\n",
    "        if j.ready():\n",
    "            ready += 1\n",
    "    return \"%d/%d\" % (ready, len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = !$bowtie2_build -f $assembly $assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#modified from read_mapping notebook to align with LB and PL in @RG\n",
    "def run_bowtie2(args):\n",
    "    timer = stopwatch.Timer()\n",
    "    cpus = multiprocessing.cpu_count()\n",
    "    bowtie2, assembly, reads, rglb, sam = args\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False)\n",
    "    rgid = os.path.basename(reads)\n",
    "    rgsm = rgid\n",
    "    cmd = \"%s %s %s -p %d -x %s -U %s -S \\\n",
    "    %s --rg-id %s --rg SM:%s --rg PL:illumina --rg LB:%s\" % (bowtie2,\n",
    "                                                           \"--local\",\n",
    "                                                           \"--very-sensitive-local\", \n",
    "                                                           cpus, \n",
    "                                                           assembly,\n",
    "                                                           reads,\n",
    "                                                           tmp.name,\n",
    "                                                           rgid,\n",
    "                                                           rgsm,\n",
    "                                                           rglb)\n",
    "    print socket.gethostname(), cmd\n",
    "    !$cmd\n",
    "    shutil.move(tmp.name, sam)\n",
    "    timer.stop()\n",
    "    return assembly, sam, cmd, timer.elapsed\n",
    "dview['run_bowtie2'] = run_bowtie2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowtie2_jobs = []\n",
    "for f in fastq_files:\n",
    "    sample_name = get_sample_name_from_file(f)\n",
    "    rglb = library_index[sample_name]\n",
    "    sam = os.path.join(analysis_dir, \"%s_bowtie2.sam\" % os.path.basename(f))\n",
    "    bowtie2_jobs.append(hlview.apply_async(run_bowtie2, (bowtie2, assembly, f, rglb, sam)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print get_async_progress(bowtie2_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_sortsam(args):\n",
    "    java, picard, sam_file = args\n",
    "    out_bam = \"%s_sorted.bam\" % sam_file\n",
    "    t = tempfile.NamedTemporaryFile(delete=False)\n",
    "    cmd = \"%s -jar %s SortSam INPUT=%s OUTPUT=%s SORT_ORDER=coordinate\" % (java,\n",
    "                                                                               picard,\n",
    "                                                                               sam_file,\n",
    "                                                                               t.name)\n",
    "    print cmd\n",
    "    !$cmd\n",
    "    shutil.move(t.name, out_bam)\n",
    "    return cmd, out_bam\n",
    "dview['run_sortsam'] = run_sortsam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sam_files = !ls {analysis_dir}/*_bowtie2.sam\n",
    "sam_files = sorted(sam_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_sortsam((java, picard, sam_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortsam_jobs = []\n",
    "for f in sam_files:\n",
    "    sortsam_jobs.append(lview.apply_async(run_sortsam, (java, picard, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_async_progress(sortsam_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mark_duplicates(args):\n",
    "    java, picard, bam_file = args\n",
    "    out_bam = \"%s_dedup.bam\" % bam_file\n",
    "    t = tempfile.NamedTemporaryFile(delete=False)\n",
    "    cmd = \"%s -jar %s MarkDuplicates \\\n",
    "    INPUT=%s OUTPUT=%s METRICS_FILE=%s.metrics\" %     (java,\n",
    "                              picard,\n",
    "                              bam_file,\n",
    "                              t.name,\n",
    "                              out_bam)\n",
    "    print cmd\n",
    "    !$cmd\n",
    "    shutil.move(t.name, out_bam)\n",
    "    return cmd, out_bam\n",
    "dview['mark_duplicates'] = mark_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_bams = !ls {analysis_dir}/*bowtie2*_sorted.bam\n",
    "sorted_bams = sorted(sorted_bams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dedup_jobs = []\n",
    "for f in sorted_bams:\n",
    "    dedup_jobs.append(hlview.apply_async(mark_duplicates, (java, picard, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_async_progress(dedup_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bam_index(args):\n",
    "    java, picard, bam_file = args\n",
    "    cmd = \"%s -jar %s BuildBamIndex INPUT=%s\" % (java, picard, bam_file)\n",
    "    print cmd\n",
    "    !$cmd\n",
    "    return cmd\n",
    "dview['build_bam_index'] = build_bam_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dedup_bams = !ls {analysis_dir}/*bowtie2.sam_sorted.bam_dedup.bam\n",
    "dedup_bams = sorted(dedup_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_jobs = []\n",
    "for f in dedup_bams:\n",
    "    index_jobs.append(hlview.apply_async(build_bam_index, (java, picard, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_async_progress(index_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gatk = \"/home/cfriedline/data7/src/GATK3.3/GenomeAnalysisTK.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$java -jar $picard CreateSequenceDictionary REFERENCE=$assembly output={assembly}.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_realigner_target_creator(args):\n",
    "    print socket.gethostname()\n",
    "    java, gatk, assembly, bam_file_list, out_dir = args\n",
    "    out_file = os.path.join(out_dir, \"forIndelRealigner.intervals\")\n",
    "    cmd = \"%s -Xmx10G -jar %s -T RealignerTargetCreator -R %s -I %s -o %s\" % (java,\n",
    "                                                                              gatk,\n",
    "                                                                              assembly,\n",
    "                                                                              bam_file_list,\n",
    "                                                                              out_file)\n",
    "    print cmd\n",
    "    !$cmd\n",
    "    return cmd\n",
    "dview['run_realigner_target_creator'] = run_realigner_target_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"dedup_bams.list\"), \"w\") as o:\n",
    "    for f in dedup_bams:\n",
    "        o.write(\"%s\\n\" % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realiger_target_creator_job = lview.apply_async(run_realigner_target_creator, (java, \n",
    "                              gatk, \n",
    "                              assembly, \n",
    "                              \"/data7/eckertlab/projects/ethan/analysis/gatk/dedup_bams.list\",\n",
    "                              analysis_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print realiger_target_creator_job.stdout[-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_indel_realigner(args):\n",
    "    print socket.gethostname()\n",
    "    print args\n",
    "    java, gatk, assembly, bam_file_list, out_dir, intervals = args\n",
    "    cmd = \"%s -Xmx100G -jar %s -T IndelRealigner -R %s -I %s -nWayOut '%s' -targetIntervals %s\" % (java,\n",
    "                                                                                          gatk,\n",
    "                                                                                          assembly,\n",
    "                                                                                          bam_file_list,\n",
    "                                                                                          \"_cleaned.bam\",\n",
    "                                                                                          intervals)\n",
    "    print cmd\n",
    "    #!$cmd\n",
    "    return cmd\n",
    "dview['run_indel_realigner'] = run_indel_realigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indel_realiger_job = lview.apply_async(run_indel_realigner, (java,\n",
    "                                                             gatk,\n",
    "                                                             assembly,\n",
    "                                                             \"/data7/eckertlab/projects/ethan/analysis/gatk/dedup_bams.list\",\n",
    "                                                             analysis_dir,\n",
    "                                                             \"/data7/eckertlab/projects/ethan/analysis/gatk/forIndelRealigner.intervals\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this command run manually on godel in tmux\n",
    "print indel_realiger_job.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realigned_bams = !ls {analysis_dir}/*dedup_realigned.bam\n",
    "realigned_bams = sorted(realigned_bams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup base recalibration\n",
    "\n",
    "This sets up the framework for BSQR, but will be run on uncalibrated SNPs first \n",
    "per GATK best practices.  e.g., \n",
    "\n",
    "* First do an initial round of SNP calling on your original, unrecalibrated data.\n",
    "* Then take the SNPs that you have the highest confidence in and use that set as the database of known SNPs by feeding it as a VCF file to the base quality score recalibrator.\n",
    "* Finally, do a real round of SNP calling with the recalibrated data. These steps could be repeated several times until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_base_recalibrator(args):\n",
    "    java, gatk, assembly, bam_file, out_dir = args\n",
    "    cmd_args = (java, gatk, assembly, bam_file, bam_file, bam_file)\n",
    "    \n",
    "    cmd1 = \"%s -jar %s \\\n",
    "    -T BaseRecalibrator \\\n",
    "    -R %s \\\n",
    "    -I %s \\\n",
    "    -o %s_recal_data.table\" % cmd_args[:-1] \n",
    "    \n",
    "    cmd2 = \"%s -jar %s \\\n",
    "    -T BaseRecalibrator \\\n",
    "    -R %s \\\n",
    "    -I %s \\\n",
    "    -BQSR %s_recal_data.table \\\n",
    "    -o %s_post_recal_data.table\" % cmd_args\n",
    "    \n",
    "    cmd3 = \"%s -jar %s \\\n",
    "    -T AnalyzeCovariates \\\n",
    "    -R %s \\\n",
    "    -before %s_recal_data.table \\\n",
    "    -after %s_post_recal_data.table \\\n",
    "    -plots %s_recalibration_plots.pdf\" % cmd_args\n",
    "    \n",
    "    cmd4 = \"%s -jar %s \\\n",
    "    -T PrintReads \\\n",
    "    -R %s \\\n",
    "    -I %s \\\n",
    "    -BQSR %s_recal_data.table \\\n",
    "    -o %s_bsqr.bam\" % cmd_args\n",
    "    \n",
    "    print socket.gethostname()\n",
    "    \n",
    "    for cmd in [cmd1, cmd2, cmd3, cmd4]:\n",
    "        print cmd\n",
    "        !$cmd\n",
    "        \n",
    "    return [cmd1, cmd2, cmd3, cmd4]\n",
    "dview['run_base_recalibrator'] = run_base_recalibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for f in realigned_bams:\n",
    "#     bqsr_jobs.append(hlview.apply_async(run_base_recalibrator, (java, \n",
    "#                                                                 gatk, \n",
    "#                                                                 assembly, \n",
    "#                                                                 realigned_bams[0], \n",
    "#                                                                 analysis_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initial variant calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_haploptype_caller(args):\n",
    "    java, gatk, assembly, bam_file = args\n",
    "    cmd = \"%s -jar %s \\\n",
    "     -T HaplotypeCaller \\\n",
    "     -R %s \\\n",
    "     -I %s \\\n",
    "     --emitRefConfidence GVCF \\\n",
    "     --variant_index_type LINEAR \\\n",
    "     --variant_index_parameter 128000 \\\n",
    "     -o %s.raw.snps.indels.g.vcf\" % (java, \n",
    "                                     gatk,\n",
    "                                     assembly,\n",
    "                                     bam_file,\n",
    "                                     bam_file)\n",
    "    print socket.gethostname()\n",
    "    !$cmd\n",
    "    return cmd\n",
    "dview['run_haploptype_caller'] = run_haploptype_caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_jobs = []\n",
    "for f in realigned_bams:\n",
    "    var_jobs.append(hlview.apply_async(run_haploptype_caller, (java,\n",
    "                                                               gatk,\n",
    "                                                               assembly,\n",
    "                                                               f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_async_progress(var_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gvcf_files = !ls {analysis_dir}/*.g.vcf\n",
    "len(gvcf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_genotype_gvcfs(args):\n",
    "    java, gatk, vcf_files, output_dir = args\n",
    "    out_vcf = os.path.join(output_dir, \"foxtail_gatk.vcf\")\n",
    "    variant_string = \" --variant \".join(vcf_files)\n",
    "    cmd = \"%s -Xmx100g -jar %s \\\n",
    "       -R %s \\\n",
    "       -T GenotypeGVCFs \\\n",
    "       --variant %s \\\n",
    "       -o %s\" % (java, \n",
    "                 gatk,\n",
    "                 assembly,\n",
    "                 variant_string,\n",
    "                 out_vcf)\n",
    "    print socket.gethostname()\n",
    "#     !$cmd\n",
    "    return cmd\n",
    "dview['run_genotype_gvcfs'] = run_genotype_gvcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"run_gvcf.sh\"), \"w\") as o:\n",
    "    cmd = run_genotype_gvcfs((java, gatk, gvcf_files, analysis_dir))\n",
    "    o.write(\"%s\\n\" % cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
